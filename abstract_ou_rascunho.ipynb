{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perrijuan/UFRJ-Analytica-processo-seletivo/blob/main/abstract_ou_rascunho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GP1RytV4oc7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar bibliotecas de regressão (linear e logística), de score que de regressões, de estatística"
      ],
      "metadata": {
        "id": "gbQaYtjSog6G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXM30zZtwfnt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a biblioteca pandas, vou trazer o arquivo pro python"
      ],
      "metadata": {
        "id": "eShXr7niprIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "campeonatos = pd.read_csv(\"campeonatos_futebol_atualizacao.csv\")"
      ],
      "metadata": {
        "id": "6b-AGIGopjYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1c951190-30bf-42e1-b3a3-0aef1b7cd984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'campeonatos_futebol_atualizacao.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7d38ab975bda>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcampeonatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"campeonatos_futebol_atualizacao.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'campeonatos_futebol_atualizacao.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Começando a análise exploratória dos dados, vou printar a head ( 5 primeiras linhas do dataset ), depois printar o .dtypes ( para analisar o tipo de dado que vamos tratar ) e vou usar o .info para ver quantos dados faltam"
      ],
      "metadata": {
        "id": "DUYLMdyTpzqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(campeonatos.head())"
      ],
      "metadata": {
        "id": "RJXcJwAvp8o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(campeonatos.dtypes)"
      ],
      "metadata": {
        "id": "LN3DcIWMqlHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(campeonatos.info())"
      ],
      "metadata": {
        "id": "PHn2-1i3qtTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vou ver onde tem valores faltando ( ou seja, NAN ), pra isso vou usar o isnull do pandas"
      ],
      "metadata": {
        "id": "6zVrL_xisxrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_com_null = campeonatos.columns[campeonatos.isnull().any()]\n",
        "print(colunas_com_null)"
      ],
      "metadata": {
        "id": "tvcqmUS8tI9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Só para conferir se todas colunas tem valor null:"
      ],
      "metadata": {
        "id": "Qek2vOk_tzDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(colunas_com_null) == len(campeonatos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "TiuiCaKctwyi",
        "outputId": "e94e3e71-fc34-44aa-c4ae-a704b1bf0500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'colunas_com_null' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d29ebedba2ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolunas_com_null\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcampeonatos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'colunas_com_null' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora eu vou tratar as colunas numéricas que tem valor NULL, vou tentar substituir com a mediana, mas fiquem a vontade para mudar. Para isso, vou criar uma df que tenham só as colunas numéricas que tem valor null."
      ],
      "metadata": {
        "id": "0eYZtiTyt_9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_numericas_null = campeonatos[colunas_com_null].select_dtypes(include='number').columns\n"
      ],
      "metadata": {
        "id": "0VnO2S-8uUAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao inves de fazer um por um, vou fazer um for loop que vá substituindo os valores faltantes de cada coluna pela mediana."
      ],
      "metadata": {
        "id": "NxijKzNmv_0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for coluna in colunas_numericas_null:\n",
        "\n",
        "    campeonatos[coluna] = campeonatos[coluna].fillna(np.median(campeonatos[coluna]))"
      ],
      "metadata": {
        "id": "TAsyhS9uvSzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para as colunas que são do tipo 'object', eu vou fazer a mesma coisa, eu vou tentar substituir com a moda, para evitar perdermos linhas do dataframe"
      ],
      "metadata": {
        "id": "8HmSF9NMw4lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_object_null = campeonatos[colunas_com_null].select_dtypes(include = 'object').columns\n",
        "\n",
        "for coluna in colunas_object_null:\n",
        "\n",
        "  moda = campeonatos[coluna].mode()[0]\n",
        "  campeonatos[coluna] = campeonatos[coluna].fillna(moda)"
      ],
      "metadata": {
        "id": "B4dF3ktTxFrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vou identificar outliers utilizando zscore, ou seja, para modulo de zscore > 3, existe um outlier."
      ],
      "metadata": {
        "id": "Y_vlrESdzeh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "colunas_numericas = campeonatos.select_dtypes(include = 'number')\n",
        "z_scores = stats.zscore(colunas_numericas)\n",
        "outliers = (np.abs(z_scores) > 3)\n",
        "\n",
        "for coluna in colunas_numericas.columns:\n",
        "    if outliers[coluna].any():\n",
        "        print(f\"Outliers na coluna '{coluna}':\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM1T_ApCzrTu",
        "outputId": "fa0af643-5792-4ece-a19f-404dd8d83576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers na coluna 'Cartões amarelos 1':\n",
            "Outliers na coluna 'Cartões amarelos 2':\n",
            "Outliers na coluna 'Cartões vermelhos 1':\n",
            "Outliers na coluna 'Cartões vermelhos 2':\n",
            "Outliers na coluna 'Gols 1':\n",
            "Outliers na coluna 'Gols 2':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função que limpa os dados de um dataframe."
      ],
      "metadata": {
        "id": "UFyCILFOAad3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dataset_limpo_para_csv(df, nome_arquivo='dataset_limpo.csv'):\n",
        "    colunas_com_null = df.columns[df.isnull().any()]\n",
        "\n",
        "    colunas_numericas_null = df[colunas_com_null].select_dtypes(include='number').columns\n",
        "    for coluna in colunas_numericas_null:\n",
        "        df[coluna] = df[coluna].fillna(np.median(df[coluna]))\n",
        "\n",
        "    colunas_object_null = df[colunas_com_null].select_dtypes(include='object').columns\n",
        "    for coluna in colunas_object_null:\n",
        "        moda = df[coluna].mode()[0]\n",
        "        df[coluna] = df[coluna].fillna(moda)\n",
        "\n",
        "    colunas_numericas = df.select_dtypes(include='number')\n",
        "    z_scores = stats.zscore(colunas_numericas)\n",
        "    outliers = (np.abs(z_scores) > 3)\n",
        "    linhas_sem_outliers = ~(outliers.any(axis=1))\n",
        "    df = df[linhas_sem_outliers]\n",
        "\n",
        "    df.to_csv(nome_arquivo, index=False)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "LoW4FxPZAZcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vou criar duas funções para padronizar os dados com o StandarScaler e outra\n"
      ],
      "metadata": {
        "id": "YRW5K--p-4pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ------------------------------------------------"
      ],
      "metadata": {
        "id": "YM3DpG2fNz1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def padronizar_dados(df):\n",
        "    scaler = StandardScaler()\n",
        "    col_num = df.select_dtypes(include='number').columns\n",
        "    df_standard = df.copy()\n",
        "    df_standard[col_num] = scaler.fit_transform(df[col_num])\n",
        "\n",
        "    return df_standard\n"
      ],
      "metadata": {
        "id": "eHniMEgz9HSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# algoritimos de ml e implementação de metricas"
      ],
      "metadata": {
        "id": "r6fnaEHON6Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import io\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_curve, auc, confusion_matrix,\n",
        "                            classification_report, roc_auc_score)\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Verificar disponibilidade do XGBoost -> a consertar\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    xgboost_available = True\n",
        "except ImportError:\n",
        "    xgboost_available = False\n",
        "    print(\"XGBoost não está instalado. Para instalar, execute: !pip install xgboost\")\n",
        "\n",
        "# Configurações globais de visualização\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Classe responsável pelo carregamento de dados.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_from_upload() -> pd.DataFrame:\n",
        "        \"\"\"Carrega dados via upload no Google Colab.\"\"\"\n",
        "        print(\"Por favor, faça upload do arquivo CSV:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for fn in uploaded.keys():\n",
        "            print(f'Arquivo carregado: {fn}')\n",
        "            df = pd.read_csv(io.BytesIO(uploaded[fn]))\n",
        "            return df\n",
        "\n",
        "        raise ValueError(\"Nenhum arquivo foi carregado.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_from_drive(path: str) -> pd.DataFrame:\n",
        "        \"\"\"Carrega dados do Google Drive.\"\"\"\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        df = pd.read_csv(path)\n",
        "        return df\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Classe responsável pelo pré-processamento de dados.\"\"\"\n",
        "\n",
        "    def __init__(self, random_state: int = 42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = None\n",
        "\n",
        "    def preprocess(self, df: pd.DataFrame, target_column: str, test_size: float = 0.25) -> Tuple:\n",
        "        \"\"\"Pré-processa os dados para treino e teste.\"\"\"\n",
        "        # Verificar e tratar valores nulos\n",
        "        self._handle_missing_values(df)\n",
        "\n",
        "        # Separar recursos e alvo\n",
        "        X = df.drop(target_column, axis=1)\n",
        "        y = df[target_column]\n",
        "\n",
        "        # Codificar variáveis categóricas\n",
        "        X = self._encode_categorical_features(X)\n",
        "        self.feature_names = X.columns\n",
        "\n",
        "        # Dividir em conjuntos de treino e teste\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        # Escalar características\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "    def _handle_missing_values(self, df: pd.DataFrame) -> None:\n",
        "        \"\"\"Trata valores ausentes no DataFrame.\"\"\"\n",
        "        if df.isnull().sum().sum() > 0:\n",
        "            print(\"Dados contêm valores nulos. Realizando tratamento...\")\n",
        "\n",
        "            # Preencher valores numéricos nulos com a média\n",
        "            num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "            for col in num_cols:\n",
        "                if df[col].isnull().sum() > 0:\n",
        "                    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "            # Preencher valores categóricos nulos com a moda\n",
        "            cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "            for col in cat_cols:\n",
        "                if df[col].isnull().sum() > 0:\n",
        "                    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    def _encode_categorical_features(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Codifica variáveis categóricas usando one-hot encoding.\"\"\"\n",
        "        return pd.get_dummies(X)\n",
        "\n",
        "\n",
        "class Model(ABC):\n",
        "    \"\"\"Classe base abstrata para modelos de classificação.\"\"\"\n",
        "\n",
        "    def __init__(self, name: str, model: BaseEstimator):\n",
        "        self.name = name\n",
        "        self.model = model\n",
        "        self.metrics = {}\n",
        "        self.roc_data = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Treina o modelo com os dados fornecidos.\"\"\"\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Faz previsões com o modelo treinado.\"\"\"\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Retorna as probabilidades para cada classe.\"\"\"\n",
        "        return self.model.predict_proba(X)\n",
        "\n",
        "    def get_name(self) -> str:\n",
        "        \"\"\"Retorna o nome do modelo.\"\"\"\n",
        "        return self.name\n",
        "\n",
        "    def get_metrics(self) -> Dict:\n",
        "        \"\"\"Retorna as métricas calculadas do modelo.\"\"\"\n",
        "        return self.metrics\n",
        "\n",
        "    def get_roc_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Retorna os dados da curva ROC.\"\"\"\n",
        "        return self.roc_data\n",
        "\n",
        "#Fabrica para instanciar n modelos gerando nossa comparação muito mais solida e robusta\n",
        "\n",
        "class ModelFactory:\n",
        "    \"\"\"Fábrica para criar instâncias de modelos.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_models() -> List[Model]:\n",
        "        \"\"\"Cria e retorna uma lista de todos os modelos disponíveis.\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Criar instâncias de cada modelo\n",
        "        models.append(Model(\"Regressão Logística\",\n",
        "                           LogisticRegression(max_iter=1000, random_state=42)))\n",
        "\n",
        "        models.append(Model(\"Árvore de Decisão\",\n",
        "                           DecisionTreeClassifier(max_depth=5, random_state=42)))\n",
        "\n",
        "        models.append(Model(\"KNN\",\n",
        "                           KNeighborsClassifier(n_neighbors=5)))\n",
        "\n",
        "        models.append(Model(\"Naive Bayes (Gaussian)\",\n",
        "                           GaussianNB()))\n",
        "\n",
        "        models.append(Model(\"SVM\",\n",
        "                           SVC(probability=True, random_state=42)))\n",
        "\n",
        "        models.append(Model(\"Rede Neural\",\n",
        "                           MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)))\n",
        "\n",
        "        models.append(Model(\"Random Forest\",\n",
        "                           RandomForestClassifier(n_estimators=100, random_state=42)))\n",
        "\n",
        "        models.append(Model(\"Gradient Boosting\",\n",
        "                           GradientBoostingClassifier(n_estimators=100, random_state=42)))\n",
        "\n",
        "        # Adicionar XGBoost se disponível\n",
        "        if xgboost_available:\n",
        "            models.append(Model(\"XGBoost\",\n",
        "                               XGBClassifier(n_estimators=100, random_state=42)))\n",
        "\n",
        "        return models\n",
        "\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Classe responsável pela avaliação de modelos.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate_model(model: Model, X_test, y_test) -> Model:\n",
        "        \"\"\"Avalia um modelo e calcula suas métricas de desempenho.\"\"\"\n",
        "        # Fazer previsões\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Calcular métricas básicas\n",
        "        metrics = {\n",
        "            \"Model\": model.get_name(),\n",
        "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "            \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "            \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
        "        }\n",
        "\n",
        "        # Calcular curva ROC e AUC\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        metrics[\"ROC AUC\"] = auc(fpr, tpr)\n",
        "\n",
        "        # Armazenar dados da curva ROC\n",
        "        model.roc_data = pd.DataFrame({\n",
        "            'FPR': fpr,\n",
        "            'TPR': tpr,\n",
        "            'Model': [model.get_name()] * len(fpr)\n",
        "        })\n",
        "\n",
        "        # Salvar métricas no modelo\n",
        "        model.metrics = metrics\n",
        "\n",
        "        # Imprimir relatório de classificação\n",
        "        print(f\"\\n--- Relatório de Classificação: {model.get_name()} ---\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(\"Matriz de Confusão:\")\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        print(cm)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "class ResultVisualizer:\n",
        "    \"\"\"Classe responsável por visualizar os resultados da avaliação de modelos.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.colors = sns.color_palette('viridis', 10)\n",
        "\n",
        "    def create_comparison_plots(self, results_df: pd.DataFrame, roc_results: pd.DataFrame):\n",
        "        \"\"\"Cria todos os gráficos de comparação entre modelos.\"\"\"\n",
        "        self._plot_metrics_comparison(results_df)\n",
        "        self._plot_roc_auc_comparison(results_df)\n",
        "        self._plot_roc_curves(results_df, roc_results)\n",
        "        self._plot_metrics_heatmap(results_df)\n",
        "        self._plot_radar_chart(results_df)\n",
        "\n",
        "    def _plot_metrics_comparison(self, results_df: pd.DataFrame):\n",
        "        \"\"\"Plota comparação de métricas (Acurácia, Precisão, Revocação, F1).\"\"\"\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "        results_melted = pd.melt(results_df,\n",
        "                                id_vars=['Model'],\n",
        "                                value_vars=metrics,\n",
        "                                var_name='Metric',\n",
        "                                value_name='Score')\n",
        "\n",
        "        sns.barplot(x='Model', y='Score', hue='Metric', data=results_melted)\n",
        "        plt.title('Comparação de Métricas entre Modelos', fontsize=16)\n",
        "        plt.xlabel('Modelo', fontsize=14)\n",
        "        plt.ylabel('Pontuação', fontsize=14)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.legend(title='Métrica')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_roc_auc_comparison(self, results_df: pd.DataFrame):\n",
        "        \"\"\"Plota comparação de ROC AUC como gráfico de barras.\"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ax = sns.barplot(x='Model', y='ROC AUC', data=results_df, palette=self.colors)\n",
        "        plt.title('Comparação de ROC AUC entre Modelos', fontsize=16)\n",
        "        plt.xlabel('Modelo', fontsize=14)\n",
        "        plt.ylabel('ROC AUC', fontsize=14)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "        # Adicionar valores nas barras\n",
        "        for i, v in enumerate(results_df['ROC AUC']):\n",
        "            ax.text(i, v+0.01, f'{v:.3f}', ha='center', fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_roc_curves(self, results_df: pd.DataFrame, roc_results: pd.DataFrame):\n",
        "        \"\"\"Plota curvas ROC para todos os modelos.\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Plotar linha de referência (random classifier)\n",
        "        plt.plot([0, 1], [0, 1], 'r--', label='Classificador Aleatório')\n",
        "\n",
        "        # Plotar curva ROC para cada modelo\n",
        "        for name in results_df['Model'].unique():\n",
        "            model_data = roc_results[roc_results['Model'] == name]\n",
        "            plt.plot(model_data['FPR'], model_data['TPR'],\n",
        "                    label=f\"{name} (AUC = {results_df.loc[results_df['Model'] == name, 'ROC AUC'].values[0]:.3f})\")\n",
        "\n",
        "        plt.title('Curvas ROC para Todos os Modelos', fontsize=16)\n",
        "        plt.xlabel('Taxa de Falsos Positivos (1 - Especificidade)', fontsize=14)\n",
        "        plt.ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)', fontsize=14)\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_metrics_heatmap(self, results_df: pd.DataFrame):\n",
        "        \"\"\"Plota heatmap das métricas para melhor visualização.\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        heatmap_data = results_df.set_index('Model')\n",
        "        heatmap_data = heatmap_data[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']]\n",
        "\n",
        "        sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt='.3f', linewidths=0.5)\n",
        "        plt.title('Heatmap de Métricas por Modelo', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_radar_chart(self, results_df: pd.DataFrame):\n",
        "        \"\"\"Plota gráfico radar para métricas por modelo.\"\"\"\n",
        "        # Preparar dados para gráfico radar\n",
        "        categories = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "        model_names = results_df['Model'].tolist()\n",
        "\n",
        "        # Configuração do gráfico\n",
        "        fig = plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # Número de categorias\n",
        "        N = len(categories)\n",
        "\n",
        "        # Ângulo para cada eixo\n",
        "        angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "        angles += angles[:1]  # Fechar o círculo\n",
        "\n",
        "        # Plotar para cada modelo\n",
        "        ax = plt.subplot(111, polar=True)\n",
        "\n",
        "        # Adicionar linhas do grid circular\n",
        "        plt.xticks(angles[:-1], categories, size=12)\n",
        "        ax.set_rlabel_position(0)\n",
        "        plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"],\n",
        "                  color=\"grey\", size=10)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # Plotar cada modelo\n",
        "        for i, model in enumerate(model_names):\n",
        "            values = results_df.loc[results_df['Model'] == model, categories].values.flatten().tolist()\n",
        "            values += values[:1]  # Fechar o círculo\n",
        "            ax.plot(angles, values, linewidth=2, linestyle='solid', label=model)\n",
        "            ax.fill(angles, values, alpha=0.1)\n",
        "\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "        plt.title('Gráfico Radar de Métricas por Modelo', size=18)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "class ModelComparisonSystem:\n",
        "    \"\"\"Classe principal que orquestra todo o processo de comparação de modelos.\"\"\"\n",
        "\n",
        "    def __init__(self, random_state: int = 42):\n",
        "        self.data_loader = DataLoader()\n",
        "        self.data_processor = DataProcessor(random_state=random_state)\n",
        "        self.model_factory = ModelFactory()\n",
        "        self.model_evaluator = ModelEvaluator()\n",
        "        self.result_visualizer = ResultVisualizer()\n",
        "\n",
        "        # Armazenar resultados\n",
        "        self.df = None\n",
        "        self.target_column = None\n",
        "        self.feature_names = None\n",
        "        self.models = []\n",
        "        self.results_df = None\n",
        "        self.roc_results = None\n",
        "\n",
        "    def load_data(self, option: int = 1, drive_path: str = None) -> pd.DataFrame:\n",
        "        \"\"\"Carrega dados conforme a opção escolhida.\"\"\"\n",
        "        if option == 1:\n",
        "            self.df = self.data_loader.load_from_upload()\n",
        "        elif option == 2 and drive_path:\n",
        "            self.df = self.data_loader.load_from_drive(drive_path)\n",
        "        else:\n",
        "            raise ValueError(\"Opção inválida ou caminho do drive não especificado.\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def analyze_data(self) -> None:\n",
        "        \"\"\"Analisa os dados e mostra estatísticas básicas.\"\"\"\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"Os dados não foram carregados. Use load_data() primeiro.\")\n",
        "\n",
        "        print(\"\\nPrimeiras linhas do dataset:\")\n",
        "        print(self.df.head())\n",
        "\n",
        "        print(\"\\nInformações do dataset:\")\n",
        "        print(self.df.info())\n",
        "\n",
        "        print(\"\\nEstatísticas descritivas:\")\n",
        "        print(self.df.describe())\n",
        "\n",
        "    def select_target(self, target_index: int) -> str:\n",
        "        \"\"\"Seleciona a coluna alvo para predição.\"\"\"\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"Os dados não foram carregados. Use load_data() primeiro.\")\n",
        "\n",
        "        self.target_column = self.df.columns[target_index]\n",
        "        print(f\"\\nColuna alvo selecionada: {self.target_column}\")\n",
        "        return self.target_column\n",
        "\n",
        "    def preprocess_data(self, test_size: float = 0.25) -> Tuple:\n",
        "        \"\"\"Pré-processa os dados para modelagem.\"\"\"\n",
        "        if self.df is None or self.target_column is None:\n",
        "            raise ValueError(\"Dados ou coluna alvo não definidos.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = self.data_processor.preprocess(\n",
        "            self.df, self.target_column, test_size\n",
        "        )\n",
        "        self.feature_names = self.data_processor.feature_names\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def train_and_evaluate_models(self, X_train, X_test, y_train, y_test) -> pd.DataFrame:\n",
        "        \"\"\"Treina e avalia todos os modelos.\"\"\"\n",
        "        # Obter modelos\n",
        "        self.models = self.model_factory.create_models()\n",
        "\n",
        "        # Treinar e avaliar cada modelo\n",
        "        for model in self.models:\n",
        "            print(f\"Treinando {model.get_name()}...\")\n",
        "            model.fit(X_train, y_train)\n",
        "            self.model_evaluator.evaluate_model(model, X_test, y_test)\n",
        "\n",
        "        # Coletar resultados\n",
        "        results_list = [model.get_metrics() for model in self.models]\n",
        "        self.results_df = pd.DataFrame(results_list)\n",
        "\n",
        "        # Coletar dados da curva ROC\n",
        "        roc_results_list = [model.get_roc_data() for model in self.models]\n",
        "        self.roc_results = pd.concat(roc_results_list, ignore_index=True)\n",
        "\n",
        "        return self.results_df\n",
        "\n",
        "    def visualize_results(self) -> None:\n",
        "        \"\"\"Visualiza os resultados da comparação de modelos.\"\"\"\n",
        "        if self.results_df is None or self.roc_results is None:\n",
        "            raise ValueError(\"Resultados não disponíveis. Execute train_and_evaluate_models() primeiro.\")\n",
        "\n",
        "        self.result_visualizer.create_comparison_plots(self.results_df, self.roc_results)\n",
        "\n",
        "    def save_results(self, filename: str = 'modelo_comparacao_resultados.csv') -> None:\n",
        "        \"\"\"Salva os resultados em um arquivo CSV.\"\"\"\n",
        "        if self.results_df is None:\n",
        "            raise ValueError(\"Resultados não disponíveis. Execute train_and_evaluate_models() primeiro.\")\n",
        "\n",
        "        self.results_df.to_csv(filename, index=False)\n",
        "        print(f\"\\nResultados salvos em '{filename}'\")\n",
        "\n",
        "    def save_models(self, directory: str = 'models') -> None:\n",
        "        \"\"\"Salva os modelos treinados.\"\"\"\n",
        "        import os\n",
        "\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        for model in self.models:\n",
        "            with open(f\"{directory}/{model.get_name().replace(' ', '_').lower()}.pkl\", 'wb') as f:\n",
        "                pickle.dump(model.model, f)\n",
        "\n",
        "        print(f\"\\nModelos salvos no diretório '{directory}'\")\n",
        "\n",
        "    def get_best_model(self, metric: str = 'F1 Score') -> Model:\n",
        "        \"\"\"Retorna o melhor modelo baseado na métrica especificada.\"\"\"\n",
        "        if self.results_df is None:\n",
        "            raise ValueError(\"Resultados não disponíveis. Execute train_and_evaluate_models() primeiro.\")\n",
        "\n",
        "        best_model_name = self.results_df.loc[self.results_df[metric].idxmax(), 'Model']\n",
        "\n",
        "        for model in self.models:\n",
        "            if model.get_name() == best_model_name:\n",
        "                return model\n",
        "\n",
        "        raise ValueError(f\"Modelo '{best_model_name}' não encontrado.\")\n",
        "\n",
        "\n",
        "def run_interactive():\n",
        "    \"\"\"Executa o sistema de comparação de modelos de forma interativa.\"\"\"\n",
        "    system = ModelComparisonSystem()\n",
        "\n",
        "    print(\"Bem-vindo à análise comparativa de modelos de Machine Learning!\")\n",
        "    print(\"\\n1. Carregar dados via upload\")\n",
        "    print(\"2. Carregar dados do Google Drive\")\n",
        "\n",
        "    choice = int(input(\"\\nEscolha uma opção (1/2): \"))\n",
        "\n",
        "    if choice == 1:\n",
        "        system.load_data(option=1)\n",
        "    elif choice == 2:\n",
        "        path = input(\"Insira o caminho para o arquivo CSV no Google Drive: \")\n",
        "        system.load_data(option=2, drive_path=path)\n",
        "    else:\n",
        "        print(\"Opção inválida. Usando upload padrão.\")\n",
        "        system.load_data(option=1)\n",
        "\n",
        "    # Analisar dados\n",
        "    system.analyze_data()\n",
        "\n",
        "    # Selecionar coluna alvo\n",
        "    print(\"\\nColunas disponíveis:\")\n",
        "    for i, col in enumerate(system.df.columns):\n",
        "        print(f\"{i}: {col}\")\n",
        "\n",
        "    target_idx = int(input(\"\\nEscolha o índice da coluna alvo (variável dependente): \"))\n",
        "    system.select_target(target_idx)\n",
        "\n",
        "    # Pré-processar dados\n",
        "    X_train, X_test, y_train, y_test = system.preprocess_data()\n",
        "\n",
        "    # Treinar e avaliar modelos\n",
        "    system.train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Visualizar resultados\n",
        "    system.visualize_results()\n",
        "\n",
        "    # Mostrar resultados finais\n",
        "    print(\"\\nResultados finais:\")\n",
        "    sorted_results = system.results_df.sort_values('F1 Score', ascending=False)\n",
        "    print(sorted_results)\n",
        "\n",
        "    # Salvar resultados\n",
        "    save_option = input(\"\\nDeseja salvar os resultados? (s/n): \")\n",
        "    if save_option.lower() == 's':\n",
        "        system.save_results()\n",
        "\n",
        "    # Salvar modelos\n",
        "    save_models_option = input(\"\\nDeseja salvar os modelos treinados? (s/n): \")\n",
        "    if save_models_option.lower() == 's':\n",
        "        system.save_models()\n",
        "\n",
        "    # Mostrar melhor modelo\n",
        "    best_metric = input(\"\\nQual métrica você deseja usar para selecionar o melhor modelo? (Accuracy/Precision/Recall/F1 Score/ROC AUC): \")\n",
        "    try:\n",
        "        best_model = system.get_best_model(best_metric)\n",
        "        print(f\"\\nMelhor modelo baseado em {best_metric}: {best_model.get_name()}\")\n",
        "        print(f\"Métricas do melhor modelo: {best_model.get_metrics()}\")\n",
        "    except:\n",
        "        print(\"Métrica inválida. Usando F1 Score como padrão.\")\n",
        "        best_model = system.get_best_model()\n",
        "        print(f\"\\nMelhor modelo baseado em F1 Score: {best_model.get_name()}\")\n",
        "        print(f\"Métricas do melhor modelo: {best_model.get_metrics()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_interactive()"
      ],
      "metadata": {
        "id": "cdxTASyHOA_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c50833b-a538-42ed-d882-7f13471fa352"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bem-vindo à análise comparativa de modelos de Machine Learning!\n",
            "\n",
            "1. Carregar dados via upload\n",
            "2. Carregar dados do Google Drive\n"
          ]
        }
      ]
    }
  ]
}