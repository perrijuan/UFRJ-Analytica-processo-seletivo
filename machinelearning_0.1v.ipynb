{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIL4ogao41nn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import io\n",
        "import time\n",
        "from abc import ABC\n",
        "from typing import Tuple, List, Dict\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, validation_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             classification_report, roc_curve, auc, confusion_matrix)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Check if XGBoost is available\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    xgboost_available = True\n",
        "except ImportError:\n",
        "    xgboost_available = False\n",
        "    print(\"XGBoost is not installed. To install, execute: !pip install xgboost\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# MetricTimer Class: Measures execution time for metric calculations\n",
        "# -----------------------\n",
        "class MetricTimer:\n",
        "    \"\"\"Utility class to measure execution time of a metric function.\"\"\"\n",
        "    @staticmethod\n",
        "    def time_function(func, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        elapsed = time.time() - start_time\n",
        "        return result, elapsed\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Data Loading and Processing\n",
        "# -----------------------\n",
        "class DataLoader:\n",
        "    \"\"\"Loads a CSV dataset using Google Colab upload.\"\"\"\n",
        "    @staticmethod\n",
        "    def load_data_csv() -> pd.DataFrame:\n",
        "        from google.colab import files\n",
        "        print(\"Please upload your CSV file:\")\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded.keys():\n",
        "            print(f\"File uploaded: {fn}\")\n",
        "            return pd.read_csv(io.BytesIO(uploaded[fn]))\n",
        "        raise ValueError(\"No file was uploaded.\")\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Processes the data by handling missing values, encoding categorical features, and scaling.\"\"\"\n",
        "    def __init__(self, random_state: int = 42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = None\n",
        "\n",
        "    def preprocess(self, df: pd.DataFrame, target_column: str,\n",
        "                   test_size: float = 0.25) -> Tuple[np.ndarray, np.ndarray, pd.Series, pd.Series]:\n",
        "        _handle_missing_values(df)\n",
        "        X = df.drop(target_column, axis=1)\n",
        "        y = df[target_column]\n",
        "        # One-hot encode categorical features if needed\n",
        "        X = pd.get_dummies(X)\n",
        "        self.feature_names = X.columns\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "\n",
        "def _handle_missing_values(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Handles missing values without causing chained assignment warnings.\"\"\"\n",
        "    if df.isnull().sum().sum() > 0:\n",
        "        print(\"Missing values detected. Filling them...\")\n",
        "        num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        for col in num_cols:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                df.loc[:, col] = df[col].fillna(df[col].mean())\n",
        "        cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "        for col in cat_cols:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                df.loc[:, col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Model Definition and Factory\n",
        "# -----------------------\n",
        "class Model(ABC):\n",
        "    \"\"\"Simple wrapper around a scikit-learn classifier.\"\"\"\n",
        "    def __init__(self, name: str, model):\n",
        "        self.name = name\n",
        "        self.model = model\n",
        "        self.metrics: Dict = {}\n",
        "        self.roc_data = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model.fit(X_train, y_train)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if hasattr(self.model, 'predict_proba'):\n",
        "            return self.model.predict_proba(X)\n",
        "        score = self.model.decision_function(X)\n",
        "        prob = 1 / (1 + np.exp(-score))\n",
        "        return np.vstack([1 - prob, prob]).T\n",
        "\n",
        "    def get_name(self) -> str:\n",
        "        return self.name\n",
        "\n",
        "    def get_metrics(self) -> Dict:\n",
        "        return self.metrics\n",
        "\n",
        "\n",
        "class ModelFactory:\n",
        "    \"\"\"Factory for creating all available models.\"\"\"\n",
        "    @staticmethod\n",
        "    def create_models() -> List[Model]:\n",
        "        models = []\n",
        "        models.append(Model(\"Regressão Logística\",\n",
        "                            LogisticRegression(max_iter=1000, random_state=42)))\n",
        "        models.append(Model(\"Árvore de Decisão\",\n",
        "                            DecisionTreeClassifier(max_depth=5, random_state=42)))\n",
        "        models.append(Model(\"KNN\",\n",
        "                            KNeighborsClassifier(n_neighbors=5)))\n",
        "        models.append(Model(\"Naive Bayes (Gaussian)\",\n",
        "                            GaussianNB()))\n",
        "        models.append(Model(\"SVM\",\n",
        "                            SVC(probability=True, random_state=42)))\n",
        "        # For MLPClassifier, we will later provide a tuned version via hyperparameter search.\n",
        "        models.append(Model(\"Rede Neural (MLP)\",\n",
        "                            MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)))\n",
        "        models.append(Model(\"Random Forest\",\n",
        "                            RandomForestClassifier(n_estimators=100, random_state=42)))\n",
        "        models.append(Model(\"Gradient Boosting\",\n",
        "                            GradientBoostingClassifier(n_estimators=100, random_state=42)))\n",
        "        if xgboost_available:\n",
        "            models.append(Model(\"XGBoost\",\n",
        "                                XGBClassifier(n_estimators=100, random_state=42)))\n",
        "        return models\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Hyperparameter Tuning for MLPClassifier\n",
        "# -----------------------\n",
        "class MLPHyperparameterTuner:\n",
        "    'deixei em 2 pelo o calculo das labels n'\n",
        "    \"\"\"Performs hyperparameter tuning for MLPClassifier using hold-out and k-fold CV.\"\"\"\n",
        "    @staticmethod\n",
        "    def tune(X_train, y_train, cv_folds: int = 2) -> MLPClassifier:\n",
        "        from sklearn.neural_network import MLPClassifier\n",
        "        # Define a hyperparameter grid for the MLPClassifier -> reduzir para melhor complexiadade\n",
        "        param_grid = {\n",
        "            'hidden_layer_sizes': [(50,)],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'solver': ['adam', 'sgd'],\n",
        "            'alpha': [0.0001, 0.001],\n",
        "            'learning_rate': ['constant', 'adaptive']\n",
        "        }\n",
        "        # Setup k-fold cross validation\n",
        "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "        mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
        "        grid_search = GridSearchCV(estimator=mlp,\n",
        "                                   param_grid=param_grid,\n",
        "                                   cv=cv,\n",
        "                                   scoring='f1_weighted',\n",
        "                                   n_jobs=-1,\n",
        "                                   verbose=2)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        print(\"Tuned MLPClassifier Best Parameters:\")\n",
        "        print(grid_search.best_params_)\n",
        "        print(\"Best Cross-Validation F1 Score: {:.3f}\".format(grid_search.best_score_))\n",
        "        return grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Model Evaluation with Metric Timing\n",
        "# -----------------------\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Evaluates models using sklearn.metrics and measures timing.\"\"\"\n",
        "    @staticmethod\n",
        "    def evaluate_model(model: Model, X_test, y_test) -> None:\n",
        "        y_pred = model.predict(X_test)\n",
        "        try:\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        except Exception:\n",
        "            y_pred_proba = np.zeros(len(y_test))\n",
        "        acc, acc_time = MetricTimer.time_function(accuracy_score, y_test, y_pred)\n",
        "        prec, prec_time = MetricTimer.time_function(precision_score, y_test, y_pred, average='weighted', zero_division=0)\n",
        "        rec, rec_time = MetricTimer.time_function(recall_score, y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1, f1_time = MetricTimer.time_function(f1_score, y_test, y_pred, average='weighted', zero_division=0)\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        roc_auc_val = auc(fpr, tpr)\n",
        "\n",
        "        model.metrics = {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Precision\": prec,\n",
        "            \"Recall\": rec,\n",
        "            \"F1 Score\": f1,\n",
        "            \"ROC AUC\": roc_auc_val,\n",
        "            \"Timing (s)\": {\n",
        "                \"Accuracy\": acc_time,\n",
        "                \"Precision\": prec_time,\n",
        "                \"Recall\": rec_time,\n",
        "                \"F1 Score\": f1_time\n",
        "            }\n",
        "        }\n",
        "        model.roc_data = pd.DataFrame({\n",
        "            'FPR': fpr,\n",
        "            'TPR': tpr,\n",
        "            'Model': [model.get_name()] * len(fpr)\n",
        "        })\n",
        "\n",
        "        print(f\"\\n--- Evaluation Report for {model.get_name()} ---\")\n",
        "        print(\"Metrics:\")\n",
        "        for metric, value in model.metrics.items():\n",
        "            if metric != \"Timing (s)\":\n",
        "                print(f\"{metric}: {value:.3f}\")\n",
        "        print(\"Timing (in seconds):\")\n",
        "        for m, t in model.metrics[\"Timing (s)\"].items():\n",
        "            print(f\"{m}: {t:.5f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Result Visualization\n",
        "# -----------------------\n",
        "class ResultVisualizer:\n",
        "    \"\"\"Plots performance metrics and algorithm-specific illustrations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_metrics_comparison(results_df: pd.DataFrame) -> None:\n",
        "        metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"]\n",
        "        sorted_df = results_df.sort_values(by=\"F1 Score\", ascending=False)\n",
        "        melted = pd.melt(sorted_df, id_vars=[\"Model\"], value_vars=metrics,\n",
        "                         var_name=\"Metric\", value_name=\"Score\")\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.barplot(x=\"Score\", y=\"Model\", hue=\"Metric\", data=melted, palette=\"viridis\")\n",
        "        plt.title(\"Comparison of Classification Metrics Across Models\")\n",
        "        plt.xlabel(\"Score\")\n",
        "        plt.ylabel(\"Model (ordered by F1 Score)\")\n",
        "        plt.xlim(0, 1)\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_algorithm_process(model: Model, X_test, y_test) -> None:\n",
        "        \"\"\"General plots: ROC curve and Confusion Matrix.\"\"\"\n",
        "        y_pred = model.predict(X_test)\n",
        "        try:\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        except Exception:\n",
        "            y_pred_proba = np.zeros(len(y_test))\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        roc_auc_val = auc(fpr, tpr)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        fig.suptitle(f\"Process Plot for {model.get_name()}\", fontsize=16)\n",
        "        axes[0].plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC (AUC = {roc_auc_val:.2f})\")\n",
        "        axes[0].plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "        axes[0].set_xlim([0.0, 1.0])\n",
        "        axes[0].set_ylim([0.0, 1.05])\n",
        "        axes[0].set_xlabel(\"False Positive Rate\")\n",
        "        axes[0].set_ylabel(\"True Positive Rate\")\n",
        "        axes[0].set_title(\"ROC Curve\")\n",
        "        axes[0].legend(loc=\"lower right\")\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1])\n",
        "        axes[1].set_xlabel(\"Predicted Label\")\n",
        "        axes[1].set_ylabel(\"True Label\")\n",
        "        axes[1].set_title(\"Confusion Matrix\")\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_algorithm_specific(model: Model, X_test, y_test) -> None:\n",
        "        \"\"\"Creates a specific plot based on the algorithm type.\"\"\"\n",
        "        name = model.get_name()\n",
        "        X_plot = X_test[:, :2]\n",
        "        y_pred = model.predict(X_test)\n",
        "        if name == \"KNN\":\n",
        "            h = .02\n",
        "            x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1\n",
        "            y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
        "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                                 np.arange(y_min, y_max, h))\n",
        "            try:\n",
        "                Z = model.model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "            except Exception:\n",
        "                Z = np.zeros(xx.ravel().shape)\n",
        "            Z = Z.reshape(xx.shape)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.contourf(xx, yy, Z, alpha=0.4, cmap=\"coolwarm\")\n",
        "            plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y_test, s=20, edgecolor='k')\n",
        "            plt.xlabel(\"Feature 1\")\n",
        "            plt.ylabel(\"Feature 2\")\n",
        "            plt.title(\"KNN Decision Boundary\")\n",
        "            plt.show()\n",
        "        elif name == \"Regressão Logística\":\n",
        "            h = .02\n",
        "            x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1\n",
        "            y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
        "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                                 np.arange(y_min, y_max, h))\n",
        "            try:\n",
        "                Z = model.model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "            except Exception:\n",
        "                Z = np.zeros(xx.ravel().shape)\n",
        "            Z = Z.reshape(xx.shape)\n",
        "            plt.figure(figsize=(8,6))\n",
        "            plt.contourf(xx, yy, Z, alpha=0.4, cmap=\"RdBu\")\n",
        "            plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y_test, s=20, edgecolor=\"k\")\n",
        "            plt.xlabel(\"Feature 1\")\n",
        "            plt.ylabel(\"Feature 2\")\n",
        "            plt.title(\"Logistic Regression Decision Boundary\")\n",
        "            plt.show()\n",
        "        elif name == \"Árvore de Decisão\":\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plot_tree(model.model, filled=True, fontsize=8)\n",
        "            plt.title(\"Decision Tree Diagram\")\n",
        "            plt.show()\n",
        "        elif name == \"Naive Bayes (Gaussian)\":\n",
        "            try:\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "                plt.figure(figsize=(8,6))\n",
        "                plt.hist(y_pred_proba, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
        "                plt.title(\"Histogram of Predicted Probabilities (Gaussian NB)\")\n",
        "                plt.xlabel(\"Predicted Probability\")\n",
        "                plt.ylabel(\"Frequency\")\n",
        "                plt.show()\n",
        "            except Exception:\n",
        "                print(\"Predicted probabilities not available for Naive Bayes.\")\n",
        "        elif name == \"SVM\":\n",
        "            if hasattr(model.model, \"support_vectors_\"):\n",
        "                plt.figure(figsize=(8,6))\n",
        "                plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y_test, s=30, cmap=\"coolwarm\", edgecolor=\"k\")\n",
        "                sv = model.model.support_vectors_\n",
        "                plt.scatter(sv[:, 0], sv[:, 1], s=100, facecolors='none', edgecolors='k', label=\"Support Vectors\")\n",
        "                plt.xlabel(\"Feature 1\")\n",
        "                plt.ylabel(\"Feature 2\")\n",
        "                plt.title(\"SVM Support Vectors\")\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Support vectors not available or not applicable.\")\n",
        "        elif name == \"Rede Neural (MLP)\":\n",
        "            if hasattr(model.model, \"loss_curve_\"):\n",
        "                plt.figure(figsize=(8,6))\n",
        "                plt.plot(model.model.loss_curve_, marker=\"o\")\n",
        "                plt.title(\"Neural Network Loss Curve\")\n",
        "                plt.xlabel(\"Iteration\")\n",
        "                plt.ylabel(\"Loss\")\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Loss curve not available for this neural network.\")\n",
        "        elif name == \"Random Forest\":\n",
        "            try:\n",
        "                importances = model.model.feature_importances_\n",
        "                indices = np.argsort(importances)[::-1]\n",
        "                features = np.array(model.model.feature_names_in_)\n",
        "                plt.figure(figsize=(10,6))\n",
        "                plt.title(\"Random Forest Feature Importances\")\n",
        "                plt.bar(range(len(importances)), importances[indices], color=\"lightblue\", align=\"center\")\n",
        "                plt.xticks(range(len(importances)), features[indices], rotation=45)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            except Exception:\n",
        "                print(\"Feature importances not available for Random Forest.\")\n",
        "        elif name == \"Gradient Boosting\":\n",
        "            try:\n",
        "                importances = model.model.feature_importances_\n",
        "                indices = np.argsort(importances)[::-1]\n",
        "                features = np.array(model.model.feature_names_in_)\n",
        "                plt.figure(figsize=(10,6))\n",
        "                plt.title(\"Gradient Boosting Feature Importances\")\n",
        "                plt.bar(range(len(importances)), importances[indices], color=\"salmon\", align=\"center\")\n",
        "                plt.xticks(range(len(importances)), features[indices], rotation=45)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            except Exception:\n",
        "                print(\"Feature importances not available for Gradient Boosting.\")\n",
        "        elif name == \"XGBoost\":\n",
        "            try:\n",
        "                importances = model.model.feature_importances_\n",
        "                indices = np.argsort(importances)[::-1]\n",
        "                features = np.array(model.model.feature_names_in_)\n",
        "                plt.figure(figsize=(10,6))\n",
        "                plt.title(\"XGBoost Feature Importances\")\n",
        "                plt.bar(range(len(importances)), importances[indices], color=\"green\", align=\"center\")\n",
        "                plt.xticks(range(len(importances)), features[indices], rotation=45)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            except Exception:\n",
        "                print(\"Feature importances not available for XGBoost.\")\n",
        "        else:\n",
        "            ResultVisualizer.plot_algorithm_process(model, X_test, y_test)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Overall System: Model Comparison\n",
        "# -----------------------\n",
        "class ModelComparisonSystem:\n",
        "    \"\"\"Orchestrates loading CSV data from Google Colab, preprocessing, training, evaluating, and comparing models.\"\"\"\n",
        "    def __init__(self, random_state: int = 42):\n",
        "        self.data_processor = DataProcessor(random_state=random_state)\n",
        "        self.model_factory = ModelFactory()\n",
        "        self.model_evaluator = ModelEvaluator()\n",
        "        self.results_visualizer = ResultVisualizer()\n",
        "        self.df = None\n",
        "        self.target_column = None\n",
        "        self.models: List[Model] = []\n",
        "        self.results_df = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        self.df = DataLoader.load_data_csv()\n",
        "        return self.df\n",
        "\n",
        "    def analyze_data(self) -> None:\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"Data has not been loaded yet.\")\n",
        "        print(\"\\nFirst few rows:\")\n",
        "        print(self.df.head())\n",
        "        print(\"\\nData Info:\")\n",
        "        print(self.df.info())\n",
        "        print(\"\\nDescriptive Statistics:\")\n",
        "        print(self.df.describe())\n",
        "\n",
        "    def select_target(self, target_index: int) -> str:\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"Data not loaded.\")\n",
        "        self.target_column = self.df.columns[target_index]\n",
        "        print(f\"\\nSelected target column: {self.target_column}\")\n",
        "        return self.target_column\n",
        "\n",
        "    def preprocess_data(self, test_size: float = 0.25) -> Tuple:\n",
        "        if self.df is None or self.target_column is None:\n",
        "            raise ValueError(\"Data or target column not set.\")\n",
        "        X_train, X_test, y_train, y_test = self.data_processor.preprocess(\n",
        "            self.df, self.target_column, test_size\n",
        "        )\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def tune_and_replace_mlp(self, X_train, y_train) -> None:\n",
        "        \"\"\"Tune the MLPClassifier hyperparameters and replace the default MLP in the model list.\"\"\"\n",
        "        tuned_mlp = MLPHyperparameterTuner.tune(X_train, y_train, cv_folds=5)\n",
        "        for model in self.models:\n",
        "            if model.get_name() == \"Rede Neural (MLP)\":\n",
        "                model.model = tuned_mlp\n",
        "                print(\"Replaced default MLPClassifier with tuned model.\")\n",
        "                break\n",
        "\n",
        "    def train_and_evaluate_models(self, X_train, X_test, y_train, y_test) -> pd.DataFrame:\n",
        "        self.models = self.model_factory.create_models()\n",
        "        # Optionally, tune the MLPClassifier using hyperparameter tuning\n",
        "        self.tune_and_replace_mlp(X_train, y_train)\n",
        "        results = []\n",
        "        for model in self.models:\n",
        "            print(f\"\\nTraining {model.get_name()}...\")\n",
        "            model.fit(X_train, y_train)\n",
        "            self.model_evaluator.evaluate_model(model, X_test, y_test)\n",
        "            result = {\"Model\": model.get_name(), **model.metrics}\n",
        "            results.append(result)\n",
        "            self.results_visualizer.plot_algorithm_specific(model, X_test, y_test)\n",
        "        self.results_df = pd.DataFrame(results)\n",
        "        return self.results_df\n",
        "\n",
        "    def get_best_model(self, metric: str = 'F1 Score') -> Model:\n",
        "        best_model_name = self.results_df.loc[self.results_df[metric].idxmax(), 'Model']\n",
        "        for model in self.models:\n",
        "            if model.get_name() == best_model_name:\n",
        "                return model\n",
        "        raise ValueError(f\"Model '{best_model_name}' not found.\")\n",
        "\n",
        "    def visualize_results(self) -> None:\n",
        "        if self.results_df is None:\n",
        "            raise ValueError(\"No results available. Run train_and_evaluate_models() first.\")\n",
        "        self.results_visualizer.plot_metrics_comparison(self.results_df)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Run the Interactive Pipeline\n",
        "# -----------------------\n",
        "def run_interactive():\n",
        "    \"\"\"Executes the entire pipeline interactively in Google Colab using CSV input.\"\"\"\n",
        "    system = ModelComparisonSystem(random_state=42)\n",
        "    print(\"Welcome to the ML Model Comparison System (CSV input via Google Colab)!\")\n",
        "    system.load_data()\n",
        "    system.analyze_data()\n",
        "    print(\"\\nAvailable columns:\")\n",
        "    for i, col in enumerate(system.df.columns):\n",
        "        print(f\"{i}: {col}\")\n",
        "    target_index = int(input(\"\\nEnter the index of the target column: \"))\n",
        "    system.select_target(target_index)\n",
        "    X_train, X_test, y_train, y_test = system.preprocess_data(test_size=0.3)\n",
        "    system.train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
        "    print(\"\\nModel Performance Comparison:\")\n",
        "    sorted_results = system.results_df.sort_values(by=\"F1 Score\", ascending=False)\n",
        "    print(sorted_results)\n",
        "    system.visualize_results()\n",
        "    best_model = system.get_best_model(metric=\"F1 Score\")\n",
        "    print(f\"\\nBest Model: {best_model.get_name()} with F1 Score: {best_model.get_metrics()['F1 Score']:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_interactive()"
      ]
    }
  ]
}